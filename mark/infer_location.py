# # infer_location.py
# import clip
# import torch
# from PIL import Image
# import os
# from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize

# clip_model, clip_preprocess = clip.load("ViT-B/32", device="cuda" if torch.cuda.is_available() else "cpu")
# clip_device = "cuda" if torch.cuda.is_available() else "cpu"

# def get_clip_feature(img_path):
#     image = clip_preprocess(Image.open(img_path)).unsqueeze(0).to(clip_device)
#     with torch.no_grad():   
#         feature = clip_model.encode_image(image)
#     return feature / feature.norm(dim=-1, keepdim=True)

# def infer_location_clip(query_path, processed_images_dir="processed_images"):
#     query_feature = get_clip_feature(query_path)
#     max_sim = -1
#     best_location = None

#     for fname in os.listdir(processed_images_dir):
#         if not fname.endswith("_output.jpg"):
#             continue
#         location = fname.replace("_output.jpg", "")  # ä¾‹å¦‚ A01_output.jpg â†’ A01
#         base_img_path = os.path.join(processed_images_dir, fname)
#         try:
#             base_feature = get_clip_feature(base_img_path)
#             sim = (query_feature @ base_feature.T).item()
#             print(f"ğŸ“Š CLIP ç›¸ä¼¼åº¦ {location}: {sim:.4f}")
#             if sim > max_sim:
#                 max_sim = sim
#                 best_location = location
#         except Exception as e:
#             print(f"âš ï¸ ç„¡æ³•è™•ç† {fname}ï¼š{e}")
#             continue

#     return best_location





import os
from pathlib import Path
from typing import Optional, Tuple, List
import cv2
import numpy as np

# -----------------------------
# é™åˆ¶åŸ·è¡Œç·’ï¼Œé¿å…åƒæ»¿ CPU
# -----------------------------
os.environ.setdefault("OMP_NUM_THREADS", "1")
os.environ.setdefault("OPENBLAS_NUM_THREADS", "1")
os.environ.setdefault("MKL_NUM_THREADS", "1")
os.environ.setdefault("NUMEXPR_NUM_THREADS", "1")
try:
    cv2.setNumThreads(1)          # æ˜ç¢ºåªç”¨ 1 åŸ·è¡Œç·’
except Exception:
    pass
try:
    cv2.ocl.setUseOpenCL(False)   # é—œæ‰ OpenCL
except Exception:
    pass

# -----------------------------
# åƒæ•¸ï¼ˆä¾ä½ çš„ similarity_sift.pyï¼‰
# -----------------------------
MAX_WIDTH  = int(os.environ.get("SIFT_MAX_WIDTH",  "1400"))   # è®€åœ–å¾Œè‹¥å¯¬åº¦è¶…éå°±ç¸®åˆ° 1400
NFEATURES  = int(os.environ.get("SIFT_NFEATURES",  "2000"))   # SIFT ç‰¹å¾µæ•¸ï¼ˆå¯ä¾åŸæª”èª¿æ•´ï¼‰
RATIO      = float(os.environ.get("SIFT_RATIO",     "0.75"))  # Lowe ratio
MAX_DES    = int(os.environ.get("SIFT_MAX_DES",    "4000"))   # æ¯å¼µæœ€å¤šä½¿ç”¨å¤šå°‘æè¿°å­ï¼ˆåŠ é€Ÿï¼‰

_SIFT = cv2.SIFT_create(nfeatures=NFEATURES)
_BF   = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)


# -----------------------------
# å½±åƒ IO + SIFT
# -----------------------------
def _read_gray_resized(p: str, max_w: int = MAX_WIDTH) -> np.ndarray:
    img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise RuntimeError(f"ç„¡æ³•è®€åœ–: {p}")
    h, w = img.shape[:2]
    if w > max_w:
        scale = max_w / float(w)
        img = cv2.resize(img, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA)
    return img


def _compute_sift(img: np.ndarray):
    kp, des = _SIFT.detectAndCompute(img, None)
    if des is not None and len(des) > MAX_DES:
        des = des[:MAX_DES]  # æˆªæ–·åŠ é€Ÿï¼Œä¸å½±éŸ¿é‚è¼¯
    return kp, des


def _cache_path_for(img_path: str) -> str:
    return img_path + ".sift.npz"


def _load_or_compute_sift(img_path: str):
    """
    å¿«å–ï¼š{image}.sift.npz
      - kp: Nx3 (x, y, size)
      - des: SIFT æè¿°å­ (float32)
    """
    cpath = _cache_path_for(img_path)
    try:
        if os.path.exists(cpath) and os.path.getmtime(cpath) >= os.path.getmtime(img_path):
            data = np.load(cpath, allow_pickle=True)
            kparr = data["kp"]
            kp = [cv2.KeyPoint(x=float(x), y=float(y), _size=float(s)) for (x, y, s) in kparr]
            des = data["des"]
            return kp, des
    except Exception:
        pass

    img = _read_gray_resized(img_path)
    kp, des = _compute_sift(img)

    try:
        if des is not None:
            kparr = np.array([[k.pt[0], k.pt[1], k.size] for k in kp], dtype=np.float32)
            np.savez_compressed(cpath, kp=kparr, des=des)
    except Exception:
        pass

    return kp, des


def _score_pair(query_des, base_des) -> float:
    """ä»¥ Lowe ratio å– good matches æ•¸é‡ç•¶åˆ†æ•¸ï¼ˆèˆ‡ similarity_sift.py ç­‰åƒ¹ï¼‰"""
    if query_des is None or base_des is None:
        return 0.0
    matches = _BF.knnMatch(query_des, base_des, k=2)
    good = [m for m, n in matches if n is not None and m.distance < RATIO * n.distance]
    return float(len(good))


# -----------------------------
# å€™é¸æ”¶é›† & æª”åè§£æ
# -----------------------------
def _collect_candidates(base_dir: Path) -> List[str]:
    # åªæ”¶å¸¸è¦‹å½±åƒï¼š*_output.jpg/jpeg/png èˆ‡ base_*.jpg/jpeg/png
    pats = ["*_output.jpg", "*_output.jpeg", "*_output.png",
            "base_*.jpg", "base_*.jpeg", "base_*.png"]
    cands: List[str] = []
    for pat in pats:
        cands.extend(str(p) for p in sorted(base_dir.glob(pat)))
    # å»é‡
    return sorted(set(cands))


def _area_from_filename(p: str) -> str:
    stem = Path(p).stem  # "A01_output" æˆ– "base_A01"
    if stem.endswith("_output"):
        return stem[:-7]  # å»æ‰ "_output"
    if stem.startswith("base_"):
        return stem[5:]   # å»æ‰ "base_"
    return stem


# -----------------------------
# ä¸»æ¨è«–
# -----------------------------
def infer_area_by_kp(query_path: str, base_root: str, location: str) -> Optional[str]:
    """
    åœ¨ {base_root}/{location}_base_images åº•ä¸‹æ‰¾æœ€ç›¸ä¼¼çš„å€ä½ï¼ˆç”¨ SIFT+ratio testï¼‰
    å›å‚³ï¼š'A01' / 'B01' / None
    """
    base_dir = Path(base_root) / f"{location}_base_images"
    print(f"[infer] base_dir = {base_dir}")

    if not base_dir.exists():
        print(f"[infer] æ‰¾ä¸åˆ°ç›®éŒ„ï¼š{base_dir}")
        return None

    candidates = _collect_candidates(base_dir)
    print(f"[infer] candidates = {len(candidates)}")

    if not candidates:
        print(f"[infer] {base_dir} ç„¡å€™é¸åº•åœ– (*_output.*, base_*.*)")
        return None

    # æŸ¥è©¢åœ–ç‰¹å¾µ
    q_img = _read_gray_resized(query_path)
    _, q_des = _compute_sift(q_img)

    best_score, best_area = -1.0, None
    for p in candidates:
        try:
            _, b_des = _load_or_compute_sift(p)
            sc = _score_pair(q_des, b_des)
            area = _area_from_filename(p)
            print(f"[infer] {area} score={sc}")
            if sc > best_score:
                best_score, best_area = sc, area
        except Exception as e:
            print(f"[infer] æ¯”å°å¤±æ•— {p}: {e}")

    print(f"[infer] best = {best_area} (score={best_score})")
    return best_area


# -----------------------------
# èˆŠåç›¸å®¹ï¼ˆä¿ç•™å‡½å¼åï¼Œå¯¦ä½œç”¨ SIFTï¼‰
# -----------------------------
def infer_location_clip(query_path: str,
                        base_root: Optional[str] = None,
                        location: Optional[str] = None,
                        **kwargs) -> Optional[str]:
    """
    å»ºè­°å‘¼å«æ³•ï¼ˆæ–°ä»‹é¢ï¼‰ï¼š
        infer_location_clip(query, base_root, location)

    è‹¥åªå‚³ processed_images_dirï¼ˆèˆŠä»‹é¢ï¼‰ï¼Œç‚ºé¿å…æƒéå¤šæª”æ¡ˆï¼Œé€™è£¡ç›´æ¥å› Noneã€‚
    """
    if base_root and location:
        return infer_area_by_kp(query_path, base_root, location)

    # èˆŠä»‹é¢ä¸å†æ”¯æ´ï¼Œé¿å…èª¤æƒæ•´å€‹è³‡æ–™å¤¾é€ æˆé«˜è² è¼‰
    print("[infer] è«‹ä»¥ infer_location_clip(query, base_root, location) å‘¼å«")
    return None


# å‘½ä»¤åˆ—æ¸¬è©¦ï¼ˆå¯é¸ï¼‰
if __name__ == "__main__":
    import sys
    if len(sys.argv) >= 4:
        q = sys.argv[1]
        root = sys.argv[2]
        loc = sys.argv[3]
        print("RESULT:", infer_location_clip(q, root, loc) or "")
    else:
        print("ç”¨æ³•: python infer_location.py <query_path> <base_root> <location>")
